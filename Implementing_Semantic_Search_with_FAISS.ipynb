{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2FNGSr6GkwOJ2AakQytAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/o-Implementing-Semantic-Search-with-FAISS/blob/main/Implementing_Semantic_Search_with_FAISS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to implement semantic search with FAISS.\n",
        "\n",
        "For this, first, we need to install FAISS and the required packages (Skip this step if you already have FAISS installed):"
      ],
      "metadata": {
        "id": "lLqX4EmFWgUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARWInmOnWfVK",
        "outputId": "4a4b4070-185b-4503-e961-142b4a65cf92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will import the required libraries:"
      ],
      "metadata": {
        "id": "fEhdXWYqWs94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ezPfPJdbWt-7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we will load the pre-trained word embedding model (e.g., GloVe). In this example, we'll use a pre-trained GloVe model."
      ],
      "metadata": {
        "id": "P7UQCW9vW5tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/glove.6B.50d.txt'\n",
        "\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)"
      ],
      "metadata": {
        "id": "mrxHUzirW-c_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will convert the text data into numerical embeddings using the pre-trained model:"
      ],
      "metadata": {
        "id": "gUqbLxHrXOTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = [\n",
        "    'The quick brown fox jumps over the lazy dog.',\n",
        "    'The dog chased the lazy fox.',\n",
        "    'The fox and the dog are both animals.',\n",
        "    'A cat is a mammal, but not a dog.',\n",
        "    'Dogs and cats are both pets.'\n",
        "]\n",
        "\n",
        "text_embeddings = []\n",
        "\n",
        "for text in text_data:\n",
        "    text_embedding = np.mean([glove_embeddings[word] for word in text.split() if word in glove_embeddings], axis=0)\n",
        "    text_embeddings.append(text_embedding)\n",
        "\n",
        "text_embeddings = np.array(text_embeddings)"
      ],
      "metadata": {
        "id": "yuUtkb5yXPNv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use FAISS to create an index for efficient search:"
      ],
      "metadata": {
        "id": "EzETpwnoXUGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dimension = 50  # The embedding size (e.g., 50 for GloVe)\n",
        "\n",
        "# Create a Faiss index (e.g., IndexFlatL2 for L2 distance)\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Add your text embeddings to the index\n",
        "index.add(text_embeddings.astype('float32'))  # Make sure embeddings are float32\n",
        "\n",
        "# Example search: find the nearest neighbor to the first embedding\n",
        "D, I = index.search(np.expand_dims(text_embeddings[0].astype('float32'), axis=0), k=1)  # k=1 for 1 nearest neighbor\n",
        "# D contains the distances, I contains the indices of the nearest neighbors\n",
        "print(\"Nearest neighbor index:\", I[0][0])\n",
        "print(\"Distance:\", D[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em89eeqIXXgW",
        "outputId": "a98ecad5-7622-4ed6-bd97-138f9d25eb39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest neighbor index: 0\n",
            "Distance: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will search for semantically similar text:"
      ],
      "metadata": {
        "id": "6kvpqYaaXjbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = 'The fox and the dog are both animals.'\n",
        "query_embedding = np.mean([glove_embeddings[word] for word in query_text.split() if word in glove_embeddings], axis=0)\n",
        "query_embedding = np.array(query_embedding).reshape(1, -1)\n",
        "\n",
        "_, similar_indices = index.search(query_embedding, 5)\n",
        "\n",
        "similar_texts = [text_data[i] for i in similar_indices[0]]\n",
        "\n",
        "print('Similar texts to:', query_text)\n",
        "print(similar_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc_4etGmXkFN",
        "outputId": "d14a2351-1951-4775-9f78-10ba2d527d9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar texts to: The fox and the dog are both animals.\n",
            "['The fox and the dog are both animals.', 'Dogs and cats are both pets.', 'A cat is a mammal, but not a dog.', 'The quick brown fox jumps over the lazy dog.', 'The dog chased the lazy fox.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, this code performs a semantic search on a given text, query_text, using pre-trained GloVe word embeddings and the FAISS library. The text is first converted into a vector representation, called query_embedding, by averaging the embeddings of individual words in the text. The index object, which was built using a set of pre-defined texts, is used to search for the five most similar texts to the query. The similar texts are then printed."
      ],
      "metadata": {
        "id": "gdYJ7-NkXnFm"
      }
    }
  ]
}